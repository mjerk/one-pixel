<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p20" style="overflow: hidden; position: relative; background-color: white; width: 742px; height: 1100px;">
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<style type="text/css" >

#t1_20{left:70px;bottom:991px;letter-spacing:0.07px;}
#t2_20{left:472px;bottom:991px;letter-spacing:0.03px;word-spacing:0.09px;}
#t3_20{left:72px;bottom:803px;letter-spacing:-0.12px;word-spacing:0.19px;}
#t4_20{left:181px;bottom:432px;letter-spacing:-0.13px;word-spacing:0.35px;}
#t5_20{left:70px;bottom:383px;letter-spacing:0.09px;word-spacing:-1.01px;}
#t6_20{left:70px;bottom:365px;letter-spacing:0.08px;word-spacing:0.49px;}
#t7_20{left:70px;bottom:347px;letter-spacing:0.07px;word-spacing:0.7px;}
#t8_20{left:70px;bottom:328px;letter-spacing:0.08px;word-spacing:-0.03px;}
#t9_20{left:70px;bottom:310px;letter-spacing:0.09px;word-spacing:-0.07px;}
#ta_20{left:70px;bottom:292px;letter-spacing:0.09px;word-spacing:-0.04px;}
#tb_20{left:70px;bottom:273px;letter-spacing:0.07px;word-spacing:-0.92px;}
#tc_20{left:70px;bottom:255px;letter-spacing:0.08px;word-spacing:0.1px;}
#td_20{left:70px;bottom:237px;letter-spacing:0.08px;word-spacing:0.52px;}
#te_20{left:632px;bottom:237px;}
#tf_20{left:643px;bottom:237px;letter-spacing:0.11px;}
#tg_20{left:70px;bottom:219px;letter-spacing:0.08px;word-spacing:0.01px;}
#th_20{left:70px;bottom:200px;letter-spacing:0.06px;word-spacing:0.06px;}
#ti_20{left:70px;bottom:182px;letter-spacing:0.09px;word-spacing:0.03px;}
#tj_20{left:453px;bottom:182px;}
#tk_20{left:463px;bottom:182px;letter-spacing:0.08px;word-spacing:0.05px;}
#tl_20{left:70px;bottom:164px;letter-spacing:0.09px;word-spacing:0.04px;}
#tm_20{left:70px;bottom:146px;letter-spacing:0.09px;word-spacing:-0.07px;}
#tn_20{left:70px;bottom:127px;letter-spacing:0.08px;word-spacing:0.01px;}
#to_20{left:70px;bottom:109px;letter-spacing:0.05px;word-spacing:-0.01px;}
#tp_20{left:70px;bottom:91px;letter-spacing:0.09px;word-spacing:0.01px;}
#tq_20{left:70px;bottom:55px;letter-spacing:0.04px;word-spacing:0.29px;}

.s0_20{font-size:12px;font-family:LinBiolinumT_g-;color:#000;}
.s1_20{font-size:14px;font-family:LinBiolinumT_g-;color:#000;}
.s2_20{font-size:15px;font-family:LinLibertineT_h3;color:#000;}
.s3_20{font-size:15px;font-family:LinLibertineT_h3;color:#781D7D;}
.s4_20{font-size:12px;font-family:LinLibertineT_h3;color:#000;}
.t.v0_20{transform:scaleX(0.979);}
.t.v1_20{transform:scaleX(1.02);}
.t.v2_20{transform:scaleX(1.016);}
.t.v3_20{transform:scaleX(1.013);}
.t.v4_20{transform:scaleX(0.982);}
.t.v5_20{transform:scaleX(0.989);}
.t.v6_20{transform:scaleX(0.991);}
.t.v7_20{transform:scaleX(1.005);}
.t.v8_20{transform:scaleX(1.015);}
</style>
<style id="fonts20" type="text/css" >

@font-face {
	font-family: LinBiolinumT_g-;
	src: url("fonts/LinBiolinumT_g-.woff") format("woff");
}

@font-face {
	font-family: LinLibertineT_h3;
	src: url("fonts/LinLibertineT_h3.woff") format("woff");
}

</style>
<div id="pg20Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg20" style="-webkit-user-select: none;"><svg id="pdf20" width="742" height="1100" viewBox="0 0 742 1100" style="width:742px; height:1100px; z-index: 0; isolation: isolate;" version="1.1" xmlns="http://www.w3.org/2000/svg">
<defs>
</defs>
<image preserveAspectRatio="none" x="70" y="129" width="602" height="146" href="20/img/1.png"/>
<image preserveAspectRatio="none" x="160" y="319" width="422" height="319" href="20/img/2.png"/>
</svg></div>
<div class="text-container"><span id="t1_20" class="t s0_20">187:20 </span><span id="t2_20" class="t s0_20">Tom Yuviler and Dana Drachsler-Cohen </span>
<span id="t3_20" class="t s1_20">Fig. 8. The accuracy of classifiers trained to be robust and the success rate of OPPSLA on these classifiers. </span>
<span id="t4_20" class="t s1_20" data-mappings='[[47,"tt"]]'>Fig. 9. OPPSLA vs. CornerSearch for few pixel aacks on ResNet18. </span>
<span id="t5_20" class="t v0_20 s2_20">robustness to few pixel adversarial attacks. Randomized ablation employs smoothing during training </span>
<span id="t6_20" class="t v1_20 s2_20">and inference as follows. Given an input image, several variants are generated, each darkens a </span>
<span id="t7_20" class="t v1_20 s2_20" data-mappings='[[2,"ff"],[64,"fi"],[91,"fi"]]'>diﬀerent set of pixels. All variants are submitted to the classiﬁer, and the input’s classiﬁcation </span>
<span id="t8_20" class="t v2_20 s2_20">is the majority vote. For the training and inference, we rely on the authors’ code. For OPPSLA’s </span>
<span id="t9_20" class="t v1_20 s2_20" data-mappings='[[76,"fi"]]'>adversarial programs, we generate the variants upon each query to the classiﬁer and determine </span>
<span id="ta_20" class="t v3_20 s2_20" data-mappings='[[10,"fi"]]'>the classiﬁcation by the majority vote. Second, we consider an adversarial training based on our </span>
<span id="tb_20" class="t v0_20 s2_20" data-mappings='[[12,"fi"],[70,"fi"]]'>approach, deﬁned as follows: (1) it runs OPPSLA on the original classiﬁer, (2) it executes the resulting </span>
<span id="tc_20" class="t v4_20 s2_20">adversarial program on 2000 training inputs (200 of each class), (3) it adds the resulting adversarial </span>
<span id="td_20" class="t v1_20 s2_20" data-mappings='[[60,"fi"]]'>examples to the training set, and (4) it retrains the classiﬁer for 30 more epochs. Figure </span><span id="te_20" class="t v1_20 s3_20">8 </span><span id="tf_20" class="t v1_20 s2_20">(left) </span>
<span id="tg_20" class="t s2_20" data-mappings='[[38,"fi"]]'>shows the accuracy of the three classiﬁers. It shows that our adversarial training leads to a minor </span>
<span id="th_20" class="t v0_20 s2_20" data-mappings='[[22,"fi"],[76,"fi"]]'>decrease in the classiﬁer’s accuracy, in contrast to the other robust classiﬁer. Next, we run OPPSLA </span>
<span id="ti_20" class="t v5_20 s2_20" data-mappings='[[22,"fi"],[51,"fi"]]'>on the original classiﬁer and on both robust classiﬁers. Figure </span><span id="tj_20" class="t v5_20 s3_20">8 </span><span id="tk_20" class="t v5_20 s2_20">(middle / right) shows, for a given </span>
<span id="tl_20" class="t v6_20 s2_20">maximal number of queries, up to 100 / 10000, the success rate over the test set. Results show that </span>
<span id="tm_20" class="t v2_20 s2_20">our adversarial training reduces our attack’s success rate by 56% / 48% compared to our attack’s </span>
<span id="tn_20" class="t v7_20 s2_20" data-mappings='[[35,"fi"]]'>success rate on the original classiﬁer. Random ablation reduces our attack’s success rate by 74% / </span>
<span id="to_20" class="t v8_20 s2_20" data-mappings='[[36,"fi"],[93,"fi"]]'>64%, compared to the original classiﬁer. However, it comes with a cost: it reduces the classiﬁer’s </span>
<span id="tp_20" class="t s2_20">accuracy by 22%, while our approach for adversarial training only reduces it by 1%. </span>
<span id="tq_20" class="t s4_20">Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 187. Publication date: June 2023. </span></div>

</div>
</body>
</html>
