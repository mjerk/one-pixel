<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p16" style="overflow: hidden; position: relative; background-color: white; width: 742px; height: 1100px;">
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<style type="text/css" >

#t1_16{left:70px;bottom:991px;letter-spacing:0.07px;}
#t2_16{left:472px;bottom:991px;letter-spacing:0.03px;word-spacing:0.09px;}
#t3_16{left:70px;bottom:949px;letter-spacing:0.1px;word-spacing:-0.38px;}
#t4_16{left:469px;bottom:949px;letter-spacing:1.3px;}
#t5_16{left:481px;bottom:949px;}
#t6_16{left:487px;bottom:956px;}
#t7_16{left:496px;bottom:949px;}
#t8_16{left:507px;bottom:949px;}
#t9_16{left:514px;bottom:949px;}
#ta_16{left:520px;bottom:956px;}
#tb_16{left:528px;bottom:949px;}
#tc_16{left:540px;bottom:949px;}
#td_16{left:547px;bottom:949px;letter-spacing:1.14px;}
#te_16{left:557px;bottom:949px;letter-spacing:0.11px;}
#tf_16{left:595px;bottom:949px;letter-spacing:-0.08px;word-spacing:-0.02px;}
#tg_16{left:70px;bottom:930px;letter-spacing:0.09px;word-spacing:-0.06px;}
#th_16{left:305px;bottom:930px;}
#ti_16{left:317px;bottom:930px;letter-spacing:0.08px;word-spacing:-0.04px;}
#tj_16{left:70px;bottom:912px;letter-spacing:0.09px;word-spacing:-0.02px;}
#tk_16{left:70px;bottom:894px;letter-spacing:0.08px;word-spacing:-0.01px;}
#tl_16{left:70px;bottom:875px;letter-spacing:0.1px;}
#tm_16{left:93px;bottom:875px;}
#tn_16{left:99px;bottom:875px;}
#to_16{left:105px;bottom:875px;}
#tp_16{left:116px;bottom:875px;letter-spacing:0.09px;word-spacing:-0.29px;}
#tq_16{left:206px;bottom:875px;letter-spacing:0.11px;}
#tr_16{left:248px;bottom:875px;letter-spacing:0.08px;word-spacing:-0.28px;}
#ts_16{left:70px;bottom:857px;letter-spacing:0.1px;word-spacing:0.05px;}
#tt_16{left:657px;bottom:857px;}
#tu_16{left:665px;bottom:857px;}
#tv_16{left:70px;bottom:824px;}
#tw_16{left:93px;bottom:824px;letter-spacing:-0.26px;}
#tx_16{left:70px;bottom:801px;letter-spacing:0.07px;word-spacing:-0.32px;}
#ty_16{left:69px;bottom:783px;letter-spacing:0.07px;word-spacing:0.12px;}
#tz_16{left:69px;bottom:764px;letter-spacing:0.09px;word-spacing:0.07px;}
#t10_16{left:70px;bottom:746px;letter-spacing:0.09px;word-spacing:-0.01px;}
#t11_16{left:70px;bottom:728px;letter-spacing:0.07px;word-spacing:-0.09px;}
#t12_16{left:70px;bottom:709px;letter-spacing:0.07px;word-spacing:-0.16px;}
#t13_16{left:70px;bottom:691px;letter-spacing:0.08px;word-spacing:0.01px;}
#t14_16{left:85px;bottom:662px;letter-spacing:0.09px;word-spacing:0.01px;}
#t15_16{left:250px;bottom:662px;letter-spacing:0.06px;word-spacing:0.07px;}
#t16_16{left:567px;bottom:670px;}
#t17_16{left:573px;bottom:662px;letter-spacing:0.1px;word-spacing:-0.01px;}
#t18_16{left:70px;bottom:644px;letter-spacing:0.1px;word-spacing:0.01px;}
#t19_16{left:70px;bottom:626px;letter-spacing:0.12px;word-spacing:-0.54px;}
#t1a_16{left:69px;bottom:607px;letter-spacing:0.1px;}
#t1b_16{left:136px;bottom:607px;}
#t1c_16{left:146px;bottom:607px;letter-spacing:0.03px;}
#t1d_16{left:168px;bottom:607px;}
#t1e_16{left:180px;bottom:607px;}
#t1f_16{left:194px;bottom:607px;}
#t1g_16{left:201px;bottom:607px;}
#t1h_16{left:204px;bottom:607px;}
#t1i_16{left:214px;bottom:607px;letter-spacing:0.11px;}
#t1j_16{left:240px;bottom:607px;letter-spacing:0.11px;}
#t1k_16{left:304px;bottom:607px;}
#t1l_16{left:317px;bottom:607px;letter-spacing:0.1px;}
#t1m_16{left:338px;bottom:607px;letter-spacing:0.05px;word-spacing:-0.69px;}
#t1n_16{left:70px;bottom:589px;letter-spacing:0.06px;word-spacing:0.09px;}
#t1o_16{left:375px;bottom:589px;letter-spacing:0.08px;word-spacing:0.03px;}
#t1p_16{left:474px;bottom:589px;}
#t1q_16{left:481px;bottom:589px;letter-spacing:0.1px;}
#t1r_16{left:509px;bottom:589px;letter-spacing:0.08px;word-spacing:0.02px;}
#t1s_16{left:605px;bottom:589px;letter-spacing:0.1px;}
#t1t_16{left:622px;bottom:589px;}
#t1u_16{left:635px;bottom:589px;letter-spacing:0.1px;}
#t1v_16{left:652px;bottom:589px;}
#t1w_16{left:665px;bottom:589px;}
#t1x_16{left:70px;bottom:571px;letter-spacing:0.09px;word-spacing:-0.35px;}
#t1y_16{left:570px;bottom:571px;letter-spacing:0.09px;word-spacing:-0.35px;}
#t1z_16{left:631px;bottom:571px;}
#t20_16{left:638px;bottom:571px;letter-spacing:0.1px;}
#t21_16{left:666px;bottom:571px;letter-spacing:0.06px;}
#t22_16{left:70px;bottom:553px;letter-spacing:0.09px;word-spacing:-0.03px;}
#t23_16{left:155px;bottom:553px;letter-spacing:0.1px;}
#t24_16{left:180px;bottom:553px;}
#t25_16{left:193px;bottom:553px;letter-spacing:0.1px;}
#t26_16{left:218px;bottom:553px;}
#t27_16{left:231px;bottom:553px;}
#t28_16{left:242px;bottom:553px;letter-spacing:0.09px;word-spacing:-0.03px;}
#t29_16{left:70px;bottom:534px;letter-spacing:0.06px;word-spacing:-0.38px;}
#t2a_16{left:561px;bottom:534px;letter-spacing:0.1px;word-spacing:-0.44px;}
#t2b_16{left:70px;bottom:516px;letter-spacing:0.1px;word-spacing:0.05px;}
#t2c_16{left:147px;bottom:516px;letter-spacing:3.95px;}
#t2d_16{left:161px;bottom:516px;letter-spacing:0.1px;}
#t2e_16{left:175px;bottom:516px;}
#t2f_16{left:179px;bottom:516px;}
#t2g_16{left:186px;bottom:516px;letter-spacing:0.09px;word-spacing:0.05px;}
#t2h_16{left:362px;bottom:516px;letter-spacing:0.12px;}
#t2i_16{left:386px;bottom:516px;letter-spacing:0.09px;word-spacing:0.05px;}
#t2j_16{left:464px;bottom:516px;letter-spacing:0.09px;word-spacing:0.05px;}
#t2k_16{left:512px;bottom:516px;}
#t2l_16{left:519px;bottom:516px;letter-spacing:0.1px;}
#t2m_16{left:547px;bottom:516px;letter-spacing:3.95px;}
#t2n_16{left:561px;bottom:516px;letter-spacing:0.1px;}
#t2o_16{left:575px;bottom:516px;}
#t2p_16{left:579px;bottom:516px;}
#t2q_16{left:586px;bottom:516px;letter-spacing:0.1px;word-spacing:0.05px;}
#t2r_16{left:70px;bottom:498px;letter-spacing:0.09px;word-spacing:-0.33px;}
#t2s_16{left:153px;bottom:498px;letter-spacing:0.1px;}
#t2t_16{left:167px;bottom:498px;}
#t2u_16{left:170px;bottom:498px;letter-spacing:0.12px;}
#t2v_16{left:194px;bottom:498px;letter-spacing:0.1px;word-spacing:-0.35px;}
#t2w_16{left:309px;bottom:498px;letter-spacing:0.1px;word-spacing:-0.37px;}
#t2x_16{left:387px;bottom:498px;}
#t2y_16{left:394px;bottom:498px;letter-spacing:0.1px;}
#t2z_16{left:422px;bottom:498px;letter-spacing:3.57px;}
#t30_16{left:435px;bottom:498px;}
#t31_16{left:442px;bottom:498px;}
#t32_16{left:446px;bottom:498px;}
#t33_16{left:453px;bottom:498px;letter-spacing:0.09px;word-spacing:-0.33px;}
#t34_16{left:626px;bottom:498px;letter-spacing:0.1px;}
#t35_16{left:640px;bottom:498px;}
#t36_16{left:644px;bottom:498px;letter-spacing:0.12px;}
#t37_16{left:667px;bottom:498px;letter-spacing:0.06px;}
#t38_16{left:70px;bottom:480px;letter-spacing:0.09px;word-spacing:0.03px;}
#t39_16{left:599px;bottom:480px;letter-spacing:0.09px;word-spacing:0.02px;}
#t3a_16{left:70px;bottom:461px;letter-spacing:0.1px;}
#t3b_16{left:98px;bottom:461px;letter-spacing:3.95px;}
#t3c_16{left:112px;bottom:461px;}
#t3d_16{left:119px;bottom:461px;letter-spacing:0.09px;word-spacing:0.05px;}
#t3e_16{left:295px;bottom:461px;letter-spacing:0.1px;}
#t3f_16{left:309px;bottom:461px;}
#t3g_16{left:312px;bottom:461px;letter-spacing:0.12px;}
#t3h_16{left:336px;bottom:461px;letter-spacing:0.09px;word-spacing:0.05px;}
#t3i_16{left:437px;bottom:461px;letter-spacing:0.09px;word-spacing:0.05px;}
#t3j_16{left:485px;bottom:461px;}
#t3k_16{left:492px;bottom:461px;letter-spacing:0.1px;}
#t3l_16{left:520px;bottom:461px;letter-spacing:3.95px;}
#t3m_16{left:533px;bottom:461px;letter-spacing:0.1px;}
#t3n_16{left:548px;bottom:461px;}
#t3o_16{left:551px;bottom:461px;}
#t3p_16{left:558px;bottom:461px;letter-spacing:0.09px;word-spacing:0.05px;}
#t3q_16{left:70px;bottom:443px;letter-spacing:0.1px;}
#t3r_16{left:130px;bottom:443px;letter-spacing:0.1px;}
#t3s_16{left:145px;bottom:443px;}
#t3t_16{left:149px;bottom:443px;letter-spacing:0.12px;}
#t3u_16{left:173px;bottom:443px;letter-spacing:0.07px;word-spacing:0.28px;}
#t3v_16{left:70px;bottom:425px;letter-spacing:0.05px;word-spacing:0.01px;}
#t3w_16{left:70px;bottom:406px;letter-spacing:0.09px;word-spacing:0.21px;}
#t3x_16{left:70px;bottom:388px;letter-spacing:0.09px;word-spacing:-0.18px;}
#t3y_16{left:70px;bottom:370px;letter-spacing:0.06px;word-spacing:0.01px;}
#t3z_16{left:70px;bottom:352px;letter-spacing:0.09px;}
#t40_16{left:85px;bottom:323px;letter-spacing:0.08px;}
#t41_16{left:149px;bottom:323px;letter-spacing:0.06px;word-spacing:0.01px;}
#t42_16{left:70px;bottom:304px;letter-spacing:0.09px;word-spacing:-0.07px;}
#t43_16{left:256px;bottom:304px;letter-spacing:0.08px;word-spacing:-0.07px;}
#t44_16{left:302px;bottom:304px;}
#t45_16{left:309px;bottom:304px;letter-spacing:0.1px;}
#t46_16{left:338px;bottom:304px;letter-spacing:0.06px;}
#t47_16{left:70px;bottom:286px;letter-spacing:0.08px;word-spacing:-0.02px;}
#t48_16{left:71px;bottom:268px;}
#t49_16{left:76px;bottom:268px;}
#t4a_16{left:83px;bottom:268px;}
#t4b_16{left:89px;bottom:268px;}
#t4c_16{left:96px;bottom:268px;}
#t4d_16{left:102px;bottom:275px;}
#t4e_16{left:113px;bottom:268px;letter-spacing:0.09px;word-spacing:0.42px;}
#t4f_16{left:70px;bottom:250px;letter-spacing:0.04px;word-spacing:0.12px;}
#t4g_16{left:440px;bottom:257px;}
#t4h_16{left:446px;bottom:250px;letter-spacing:0.09px;}
#t4i_16{left:70px;bottom:231px;letter-spacing:0.1px;word-spacing:0.6px;}
#t4j_16{left:291px;bottom:231px;letter-spacing:0.09px;word-spacing:0.61px;}
#t4k_16{left:360px;bottom:231px;}
#t4l_16{left:368px;bottom:231px;letter-spacing:0.1px;}
#t4m_16{left:397px;bottom:231px;letter-spacing:0.08px;word-spacing:0.62px;}
#t4n_16{left:70px;bottom:213px;letter-spacing:0.08px;word-spacing:-0.05px;}
#t4o_16{left:70px;bottom:195px;letter-spacing:0.07px;word-spacing:0.03px;}
#t4p_16{left:70px;bottom:177px;letter-spacing:0.08px;word-spacing:0.01px;}
#t4q_16{left:263px;bottom:177px;letter-spacing:0.1px;word-spacing:-0.01px;}
#t4r_16{left:390px;bottom:177px;letter-spacing:0.09px;word-spacing:-0.02px;}
#t4s_16{left:70px;bottom:158px;letter-spacing:0.09px;word-spacing:0.09px;}
#t4t_16{left:70px;bottom:140px;letter-spacing:0.07px;word-spacing:0.04px;}
#t4u_16{left:70px;bottom:113px;}
#t4v_16{left:75px;bottom:108px;letter-spacing:0.08px;word-spacing:-0.01px;}
#t4w_16{left:194px;bottom:108px;letter-spacing:0.04px;}
#t4x_16{left:70px;bottom:98px;}
#t4y_16{left:75px;bottom:92px;letter-spacing:0.1px;}
#t4z_16{left:70px;bottom:55px;letter-spacing:0.04px;word-spacing:0.29px;}

.s0_16{font-size:12px;font-family:LinBiolinumT_g-;color:#000;}
.s1_16{font-size:15px;font-family:LinLibertineT_h3;color:#000;}
.s2_16{font-size:15px;font-family:txsys_hb;color:#000;}
.s3_16{font-size:15px;font-family:LinLibertineT_em;color:#000;}
.s4_16{font-size:11px;font-family:LibertineMathMI7_ev;color:#000;}
.s5_16{font-size:11px;font-family:LinLibertineT_em;color:#000;}
.s6_16{font-size:15px;font-family:Inconsolatazi4-Regular_f0;color:#000;}
.s7_16{font-size:15px;font-family:LibertineMathMI_ef;color:#000;}
.s8_16{font-size:15px;font-family:LinBiolinumTB_gw;color:#000;}
.s9_16{font-size:15px;font-family:LinLibertineTI_hf;color:#000;}
.sa_16{font-size:11px;font-family:LinLibertineT_h3;color:#781D7D;}
.sb_16{font-size:15px;font-family:LinLibertineT_h3;color:#781D7D;}
.sc_16{font-size:15px;font-family:txmiaX_er;color:#000;}
.sd_16{font-size:9px;font-family:LinLibertineT_h3;color:#000;}
.se_16{font-size:12px;font-family:LinLibertineT_h3;color:#000;}
.sf_16{font-size:12px;font-family:LinLibertineT_h3;color:#005596;}
.t.v0_16{transform:scaleX(0.979);}
.t.v1_16{transform:scaleX(1.016);}
.t.v2_16{transform:scaleX(0.983);}
.t.v3_16{transform:scaleX(0.98);}
.t.v4_16{transform:scaleX(0.988);}
.t.v5_16{transform:scaleX(0.993);}
.t.v6_16{transform:scaleX(1.02);}
.t.v7_16{transform:scaleX(0.99);}
.t.v8_16{transform:scaleX(0.987);}
.t.v9_16{transform:scaleX(1.019);}
.t.v10_16{transform:scaleX(1.008);}
.t.v11_16{transform:scaleX(1.011);}
</style>
<style id="fonts16" type="text/css" >

@font-face {
	font-family: Inconsolatazi4-Regular_f0;
	src: url("fonts/Inconsolatazi4-Regular_f0.woff") format("woff");
}

@font-face {
	font-family: LibertineMathMI7_ev;
	src: url("fonts/LibertineMathMI7_ev.woff") format("woff");
}

@font-face {
	font-family: LibertineMathMI_ef;
	src: url("fonts/LibertineMathMI_ef.woff") format("woff");
}

@font-face {
	font-family: LinBiolinumTB_gw;
	src: url("fonts/LinBiolinumTB_gw.woff") format("woff");
}

@font-face {
	font-family: LinBiolinumT_g-;
	src: url("fonts/LinBiolinumT_g-.woff") format("woff");
}

@font-face {
	font-family: LinLibertineTI_hf;
	src: url("fonts/LinLibertineTI_hf.woff") format("woff");
}

@font-face {
	font-family: LinLibertineT_em;
	src: url("fonts/LinLibertineT_em.woff") format("woff");
}

@font-face {
	font-family: LinLibertineT_h3;
	src: url("fonts/LinLibertineT_h3.woff") format("woff");
}

@font-face {
	font-family: txmiaX_er;
	src: url("fonts/txmiaX_er.woff") format("woff");
}

@font-face {
	font-family: txsys_hb;
	src: url("fonts/txsys_hb.woff") format("woff");
}

</style>
<div id="pg16Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg16" style="-webkit-user-select: none;"><svg id="pdf16" width="742" height="1100" viewBox="0 0 742 1100" style="width:742px; height:1100px; z-index: 0; isolation: isolate;" version="1.1" xmlns="http://www.w3.org/2000/svg">
<defs>
<style>
.g0_16{fill:none;stroke:#000;stroke-width:0.608;stroke-miterlimit:10;}
</style>
</defs>
<path d="M70 972.1h73.1" class="g0_16"/>
</svg></div>
<div class="text-container"><span id="t1_16" class="t s0_16">187:16 </span><span id="t2_16" class="t s0_16">Tom Yuviler and Dana Drachsler-Cohen </span>
<span id="t3_16" class="t v0_16 s1_16">number of additional queries posed to the network is bounded by </span><span id="t4_16" class="t s2_16">[( </span><span id="t5_16" class="t v0_16 s3_16">2 </span>
<span id="t6_16" class="t s4_16"> </span>
<span id="t7_16" class="t s2_16">+ </span><span id="t8_16" class="t v0_16 s3_16">1</span><span id="t9_16" class="t s2_16">) </span>
<span id="ta_16" class="t s5_16">3 </span>
<span id="tb_16" class="t s2_16">− </span><span id="tc_16" class="t v0_16 s3_16">8</span><span id="td_16" class="t s2_16">]·</span><span id="te_16" class="t s6_16">MAX_G</span><span id="tf_16" class="t v0_16 s1_16">. Technically, </span>
<span id="tg_16" class="t v1_16 s1_16">OPPSLA plants in the priority queue </span><span id="th_16" class="t s7_16"> </span><span id="ti_16" class="t v1_16 s1_16" data-mappings='[[2,"fl"]]'>a ﬂag and runs the adversarial program, while recording </span>
<span id="tj_16" class="t v0_16 s1_16" data-mappings='[[15,"fi"],[24,"ff"]]'>the maximal conﬁdence diﬀerence in the true class before and after the perturbation, for each pixel </span>
<span id="tk_16" class="t s1_16" data-mappings='[[27,"fl"],[63,"fi"]]'>location. When it pops the ﬂag from the queue, it attempts all ﬁner granularity values (excluding </span>
<span id="tl_16" class="t v0_16 s1_16">the </span><span id="tm_16" class="t v0_16 s3_16">0</span><span id="tn_16" class="t s7_16">, </span><span id="to_16" class="t v0_16 s3_16">1 </span><span id="tp_16" class="t v0_16 s1_16">values) for the </span><span id="tq_16" class="t s6_16">MAX_G </span><span id="tr_16" class="t v0_16 s1_16" data-mappings='[[30,"fi"],[39,"ff"],[64,"fl"]]'>locations with the highest conﬁdence diﬀerence. The role of the ﬂag is </span>
<span id="ts_16" class="t v2_16 s1_16" data-mappings='[[9,"fi"]]'>to check ﬁner granularity perturbations only for pairs that have not been pushed to the back of </span><span id="tt_16" class="t s7_16"></span><span id="tu_16" class="t v2_16 s1_16">. </span>
<span id="tv_16" class="t s8_16">6 </span><span id="tw_16" class="t s8_16">EVALUATION </span>
<span id="tx_16" class="t v0_16 s1_16" data-mappings='[[40,"fi"]]'>In this section, we evaluate OPPSLA. We ﬁrst describe the implementation and the evaluation setup. </span>
<span id="ty_16" class="t v3_16 s1_16">We then present our experiments that show that (1) OPPSLA obtains a state-of-the-art success rate </span>
<span id="tz_16" class="t v4_16 s1_16" data-mappings='[[10,"fi"]]'>with signiﬁcantly fewer queries, (2) our conditions enable to reduce the number of queries, (3) our </span>
<span id="t10_16" class="t v0_16 s1_16" data-mappings='[[94,"fi"]]'>adversarial programs are transferable, (4) the number of synthesis queries posed to the classiﬁer by </span>
<span id="t11_16" class="t v0_16 s1_16">OPPSLA is relatively low, (5) integrating OPPSLA in an adversarial training can reduce our attack’s </span>
<span id="t12_16" class="t v0_16 s1_16" data-mappings='[[46,"fi"]]'>success rate with a minor impact on the classiﬁer’s accuracy, (6) our few pixel attacks require fewer </span>
<span id="t13_16" class="t s1_16" data-mappings='[[21,"fi"]]'>queries, and (7) our ﬁner granularity perturbations slightly improve the success rate. </span>
<span id="t14_16" class="t s9_16">Implementation and setup. </span><span id="t15_16" class="t s1_16">We implemented OPPSLA in Python using Pytorch </span>
<span id="t16_16" class="t sa_16">5 </span>
<span id="t17_16" class="t s1_16">. Our implemen- </span>
<span id="t18_16" class="t v0_16 s1_16">tation supports GPU parallelization. Experiments ran on an Ubuntu 20.04 OS on a dual AMD EPYC </span>
<span id="t19_16" class="t v0_16 s1_16">7742 server with 1TB RAM and eight NVIDIA GeForce RTX 2080 Ti GPUs. The hyper-parameters of </span>
<span id="t1a_16" class="t v0_16 s1_16">Algorithm </span><span id="t1b_16" class="t v0_16 sb_16">2 </span><span id="t1c_16" class="t v0_16 s1_16">are </span><span id="t1d_16" class="t s7_16"> </span><span id="t1e_16" class="t sc_16">= </span><span id="t1f_16" class="t v0_16 s3_16">0</span><span id="t1g_16" class="t s7_16">.</span><span id="t1h_16" class="t v0_16 s3_16">4 </span><span id="t1i_16" class="t v0_16 s1_16">and </span><span id="t1j_16" class="t s6_16">MAX_ITER </span><span id="t1k_16" class="t sc_16">= </span><span id="t1l_16" class="t v0_16 s3_16">210</span><span id="t1m_16" class="t v0_16 s1_16">. For few pixel attacks, the top-K is top-100. We evaluate </span>
<span id="t1n_16" class="t v5_16 s1_16">OPPSLA on two image datasets. First, CIFAR-10 [</span><span id="t1o_16" class="t v5_16 sb_16">Krizhevsky et al</span><span id="t1p_16" class="t sb_16">. </span><span id="t1q_16" class="t v5_16 sb_16">2009</span><span id="t1r_16" class="t v5_16 s1_16">], consisting of </span><span id="t1s_16" class="t v5_16 s3_16">32 </span><span id="t1t_16" class="t s2_16">× </span><span id="t1u_16" class="t v5_16 s3_16">32 </span><span id="t1v_16" class="t s2_16">× </span><span id="t1w_16" class="t v5_16 s3_16">3 </span>
<span id="t1x_16" class="t v0_16 s1_16" data-mappings='[[30,"fi"]]'>colored images, each is classiﬁed as one of ten possible classes. Second, ImageNet [</span><span id="t1y_16" class="t v0_16 sb_16">Deng et al</span><span id="t1z_16" class="t sb_16">. </span><span id="t20_16" class="t v0_16 sb_16">2009</span><span id="t21_16" class="t v0_16 s1_16">], </span>
<span id="t22_16" class="t v6_16 s1_16">consisting of </span><span id="t23_16" class="t v6_16 s3_16">224 </span><span id="t24_16" class="t s2_16">× </span><span id="t25_16" class="t v6_16 s3_16">224 </span><span id="t26_16" class="t s2_16">× </span><span id="t27_16" class="t v6_16 s3_16">3 </span><span id="t28_16" class="t v6_16 s1_16" data-mappings='[[30,"fi"]]'>colored images, each is classiﬁed as one of 1000 possible classes. For </span>
<span id="t29_16" class="t v0_16 s1_16">CIFAR-10, we use three pre-trained convolutional neural networks: VGG-16-BN [</span><span id="t2a_16" class="t v0_16 sb_16">Simonyan and Zis- </span>
<span id="t2b_16" class="t v7_16 sb_16">serman 2015</span><span id="t2c_16" class="t v7_16 s1_16">](</span><span id="t2d_16" class="t v7_16 s3_16">33</span><span id="t2e_16" class="t s7_16">.</span><span id="t2f_16" class="t v7_16 s3_16">6</span><span id="t2g_16" class="t v7_16 s1_16">M parameters, test accuracy </span><span id="t2h_16" class="t v7_16 s3_16">94%</span><span id="t2i_16" class="t v7_16 s1_16">), ResNet18 [</span><span id="t2j_16" class="t v7_16 sb_16">He et al</span><span id="t2k_16" class="t sb_16">. </span><span id="t2l_16" class="t v7_16 sb_16">2016</span><span id="t2m_16" class="t v7_16 s1_16">](</span><span id="t2n_16" class="t v7_16 s3_16">11</span><span id="t2o_16" class="t s7_16">.</span><span id="t2p_16" class="t v7_16 s3_16">2</span><span id="t2q_16" class="t v7_16 s1_16">M parameters, </span>
<span id="t2r_16" class="t v0_16 s1_16">test accuracy </span><span id="t2s_16" class="t v0_16 s3_16">93</span><span id="t2t_16" class="t s7_16">.</span><span id="t2u_16" class="t v0_16 s3_16">07%</span><span id="t2v_16" class="t v0_16 s1_16">), and GoogLeNet [</span><span id="t2w_16" class="t v0_16 sb_16">Szegedy et al</span><span id="t2x_16" class="t sb_16">. </span><span id="t2y_16" class="t v0_16 sb_16">2015</span><span id="t2z_16" class="t v0_16 s1_16">](</span><span id="t30_16" class="t v0_16 s3_16">5</span><span id="t31_16" class="t s7_16">.</span><span id="t32_16" class="t v0_16 s3_16">5</span><span id="t33_16" class="t v0_16 s1_16">M parameters, test accuracy </span><span id="t34_16" class="t v0_16 s3_16">92</span><span id="t35_16" class="t s7_16">.</span><span id="t36_16" class="t v0_16 s3_16">85%</span><span id="t37_16" class="t v0_16 s1_16">). </span>
<span id="t38_16" class="t s1_16">For ImageNet, we use two pre-trained convolutional neural networks: DenseNet121 [</span><span id="t39_16" class="t sb_16">Huang et al. </span>
<span id="t3a_16" class="t v8_16 sb_16">2017</span><span id="t3b_16" class="t v8_16 s1_16">](</span><span id="t3c_16" class="t v8_16 s3_16">8</span><span id="t3d_16" class="t v8_16 s1_16">M parameters, test accuracy </span><span id="t3e_16" class="t v8_16 s3_16">74</span><span id="t3f_16" class="t s7_16">.</span><span id="t3g_16" class="t v8_16 s3_16">43%</span><span id="t3h_16" class="t v8_16 s1_16">) and ResNet50 [</span><span id="t3i_16" class="t v8_16 sb_16">He et al</span><span id="t3j_16" class="t sb_16">. </span><span id="t3k_16" class="t v8_16 sb_16">2016</span><span id="t3l_16" class="t v8_16 s1_16">](</span><span id="t3m_16" class="t v8_16 s3_16">25</span><span id="t3n_16" class="t s7_16">.</span><span id="t3o_16" class="t v8_16 s3_16">6</span><span id="t3p_16" class="t v8_16 s1_16">M parameters, test </span>
<span id="t3q_16" class="t v6_16 s1_16">accuracy </span><span id="t3r_16" class="t v6_16 s3_16">76</span><span id="t3s_16" class="t s7_16">.</span><span id="t3t_16" class="t v6_16 s3_16">13%</span><span id="t3u_16" class="t v6_16 s1_16">). For every CIFAR-10 network, we run OPPSLA with ten training sets, one for </span>
<span id="t3v_16" class="t v9_16 s1_16">each class, each consisting of 50 images. We evaluate the adversarial programs over CIFAR-10’s </span>
<span id="t3w_16" class="t v6_16 s1_16" data-mappings='[[61,"fi"]]'>test set, consisting of 1000 images for each class (misclassiﬁed images are discarded). For every </span>
<span id="t3x_16" class="t v0_16 s1_16" data-mappings='[[69,"ff"]]'>ImageNet network, we run OPPSLA with 11 training sets, each with a diﬀerent class and consisting </span>
<span id="t3y_16" class="t v10_16 s1_16">of only ten images. We evaluate the adversarial programs over a test set, consisting of 50 images </span>
<span id="t3z_16" class="t s1_16" data-mappings='[[25,"fi"]]'>for each class (misclassiﬁed images are discarded). </span>
<span id="t40_16" class="t v11_16 s9_16">Baselines. </span><span id="t41_16" class="t v11_16 s1_16" data-mappings='[[76,"fi"]]'>We compare OPPSLA to several black-box one pixel and few pixel attacks. The ﬁrst </span>
<span id="t42_16" class="t v9_16 s1_16">baseline is One Pixel Attack [</span><span id="t43_16" class="t v9_16 sb_16">Su et al</span><span id="t44_16" class="t sb_16">. </span><span id="t45_16" class="t v9_16 sb_16">2017</span><span id="t46_16" class="t v9_16 s1_16" data-mappings='[[42,"ff"]]'>], which we denote by SuOPA, relying on diﬀerential </span>
<span id="t47_16" class="t v11_16 s1_16">evolution to compute one pixel attacks. Unlike OPPSLA, SuOPA considers every perturbation in </span>
<span id="t48_16" class="t s2_16">[</span><span id="t49_16" class="t v6_16 s3_16">0</span><span id="t4a_16" class="t s7_16">, </span><span id="t4b_16" class="t v6_16 s3_16">1</span><span id="t4c_16" class="t s2_16">] </span>
<span id="t4d_16" class="t s5_16">3 </span>
<span id="t4e_16" class="t v6_16 s1_16">(and not only the eight corners of the RGB color cube), and it does not aim to minimize </span>
<span id="t4f_16" class="t v6_16 s1_16">the number of queries. We use the code from Torchattacks </span>
<span id="t4g_16" class="t sa_16">6 </span>
<span id="t4h_16" class="t v6_16 s1_16">, with the default hyper-parameters. </span>
<span id="t4i_16" class="t v6_16 s1_16">The second baseline is Sparse-RS [</span><span id="t4j_16" class="t v6_16 sb_16">Croce et al</span><span id="t4k_16" class="t sb_16">. </span><span id="t4l_16" class="t v6_16 sb_16">2022</span><span id="t4m_16" class="t v6_16 s1_16">], the state-of-the-art for one pixel and few </span>
<span id="t4n_16" class="t v11_16 s1_16">pixel attacks. It relies on random search. As mentioned, its perturbations are limited to the eight </span>
<span id="t4o_16" class="t s1_16">corners of the RGB color cube. We use the authors’ code, with the default hyper-parameters. The </span>
<span id="t4p_16" class="t v0_16 s1_16">third baseline is CornerSearch [</span><span id="t4q_16" class="t v0_16 sb_16">Croce and Hein 2019</span><span id="t4r_16" class="t v0_16 s1_16">], a few pixel attack minimizing the number of </span>
<span id="t4s_16" class="t v6_16 s1_16">perturbed pixels. It relies on local search and limits its perturbations to the eight corners of the </span>
<span id="t4t_16" class="t s1_16">RGB color cube. We use the authors’ code, with the default hyper-parameters. </span>
<span id="t4u_16" class="t sd_16">5 </span>
<span id="t4v_16" class="t se_16">The code is available at </span><span id="t4w_16" class="t sf_16">https://github.com/TomYuviler/OPPSLA </span>
<span id="t4x_16" class="t sd_16">6 </span>
<span id="t4y_16" class="t sf_16">https://github.com/Harry24k/adversarial-attacks-pytorch </span>
<span id="t4z_16" class="t se_16">Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 187. Publication date: June 2023. </span></div>

</div>
</body>
</html>
