<!DOCTYPE html>
<html>
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p4" style="overflow: hidden; position: relative; background-color: white; width: 742px; height: 1100px;">
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
.text-container {
	white-space: pre;
}
@supports (-webkit-touch-callout: none) {
	.text-container {
		white-space: normal;
	}
}
</style>
<style type="text/css" >

#t1_4{left:70px;bottom:991px;letter-spacing:0.07px;}
#t2_4{left:472px;bottom:991px;letter-spacing:0.03px;word-spacing:0.09px;}
#t3_4{left:70px;bottom:949px;letter-spacing:0.09px;word-spacing:0.07px;}
#t4_4{left:70px;bottom:930px;letter-spacing:0.09px;}
#t5_4{left:85px;bottom:912px;letter-spacing:0.06px;word-spacing:0.33px;}
#t6_4{left:70px;bottom:894px;letter-spacing:0.07px;}
#t7_4{left:70px;bottom:875px;letter-spacing:0.07px;word-spacing:-0.58px;}
#t8_4{left:70px;bottom:857px;letter-spacing:0.07px;word-spacing:-0.45px;}
#t9_4{left:70px;bottom:839px;letter-spacing:0.08px;word-spacing:-0.01px;}
#ta_4{left:70px;bottom:821px;letter-spacing:0.09px;word-spacing:-0.22px;}
#tb_4{left:70px;bottom:802px;letter-spacing:0.08px;word-spacing:0.03px;}
#tc_4{left:70px;bottom:784px;letter-spacing:0.06px;word-spacing:-0.43px;}
#td_4{left:69px;bottom:766px;letter-spacing:0.07px;word-spacing:-0.31px;}
#te_4{left:70px;bottom:748px;letter-spacing:0.09px;word-spacing:0.94px;}
#tf_4{left:70px;bottom:729px;letter-spacing:0.07px;word-spacing:-0.33px;}
#tg_4{left:70px;bottom:711px;letter-spacing:0.09px;word-spacing:-0.58px;}
#th_4{left:70px;bottom:693px;letter-spacing:0.11px;}
#ti_4{left:88px;bottom:693px;letter-spacing:0.12px;}
#tj_4{left:115px;bottom:693px;letter-spacing:0.08px;word-spacing:-0.32px;}
#tk_4{left:70px;bottom:675px;letter-spacing:0.08px;word-spacing:-0.21px;}
#tl_4{left:70px;bottom:656px;letter-spacing:0.1px;word-spacing:0.17px;}
#tm_4{left:70px;bottom:638px;letter-spacing:0.07px;word-spacing:0.05px;}
#tn_4{left:70px;bottom:620px;letter-spacing:0.09px;word-spacing:-0.24px;}
#to_4{left:70px;bottom:602px;letter-spacing:0.07px;word-spacing:0.04px;}
#tp_4{left:70px;bottom:583px;letter-spacing:0.08px;word-spacing:0.05px;}
#tq_4{left:243px;bottom:583px;}
#tr_4{left:257px;bottom:583px;letter-spacing:5.06px;}
#ts_4{left:276px;bottom:583px;}
#tt_4{left:283px;bottom:583px;letter-spacing:2.92px;}
#tu_4{left:314px;bottom:583px;letter-spacing:0.1px;}
#tv_4{left:328px;bottom:583px;}
#tw_4{left:338px;bottom:583px;letter-spacing:0.06px;word-spacing:0.11px;}
#tx_4{left:636px;bottom:583px;letter-spacing:0.1px;}
#ty_4{left:70px;bottom:565px;letter-spacing:0.1px;word-spacing:0.24px;}
#tz_4{left:161px;bottom:565px;letter-spacing:0.09px;word-spacing:0.23px;}
#t10_4{left:70px;bottom:547px;letter-spacing:0.07px;word-spacing:0.06px;}
#t11_4{left:85px;bottom:528px;letter-spacing:0.05px;word-spacing:0.09px;}
#t12_4{left:94px;bottom:510px;}
#t13_4{left:107px;bottom:510px;letter-spacing:0.09px;word-spacing:0.42px;}
#t14_4{left:107px;bottom:492px;letter-spacing:0.08px;}
#t15_4{left:107px;bottom:473px;letter-spacing:0.08px;word-spacing:0.06px;}
#t16_4{left:107px;bottom:455px;letter-spacing:0.09px;}
#t17_4{left:94px;bottom:437px;}
#t18_4{left:107px;bottom:437px;letter-spacing:0.09px;word-spacing:-0.05px;}
#t19_4{left:107px;bottom:419px;letter-spacing:0.09px;word-spacing:0.03px;}
#t1a_4{left:107px;bottom:400px;letter-spacing:0.09px;}
#t1b_4{left:94px;bottom:382px;}
#t1c_4{left:107px;bottom:382px;letter-spacing:0.08px;word-spacing:-0.22px;}
#t1d_4{left:107px;bottom:364px;letter-spacing:0.09px;}
#t1e_4{left:94px;bottom:346px;}
#t1f_4{left:107px;bottom:346px;letter-spacing:0.06px;word-spacing:-0.02px;}
#t1g_4{left:107px;bottom:327px;letter-spacing:0.09px;word-spacing:0.15px;}
#t1h_4{left:107px;bottom:309px;letter-spacing:0.08px;word-spacing:0.2px;}
#t1i_4{left:107px;bottom:291px;letter-spacing:0.08px;word-spacing:0.02px;}
#t1j_4{left:70px;bottom:255px;}
#t1k_4{left:93px;bottom:255px;letter-spacing:0.13px;}
#t1l_4{left:70px;bottom:232px;letter-spacing:0.07px;word-spacing:0.06px;}
#t1m_4{left:70px;bottom:214px;letter-spacing:0.11px;}
#t1n_4{left:96px;bottom:214px;}
#t1o_4{left:104px;bottom:214px;}
#t1p_4{left:114px;bottom:214px;letter-spacing:0.07px;word-spacing:0.05px;}
#t1q_4{left:85px;bottom:183px;letter-spacing:0.08px;word-spacing:0.09px;}
#t1r_4{left:247px;bottom:183px;letter-spacing:0.07px;word-spacing:0.13px;}
#t1s_4{left:70px;bottom:165px;letter-spacing:0.1px;word-spacing:-0.04px;}
#t1t_4{left:568px;bottom:165px;}
#t1u_4{left:576px;bottom:165px;}
#t1v_4{left:585px;bottom:165px;}
#t1w_4{left:597px;bottom:165px;}
#t1x_4{left:605px;bottom:165px;}
#t1y_4{left:615px;bottom:165px;letter-spacing:0.09px;word-spacing:-0.03px;}
#t1z_4{left:70px;bottom:147px;letter-spacing:0.08px;word-spacing:-0.01px;}
#t20_4{left:321px;bottom:147px;}
#t21_4{left:327px;bottom:147px;}
#t22_4{left:333px;bottom:147px;}
#t23_4{left:339px;bottom:147px;}
#t24_4{left:346px;bottom:147px;}
#t25_4{left:352px;bottom:154px;}
#t26_4{left:358px;bottom:147px;letter-spacing:0.08px;word-spacing:-0.01px;}
#t27_4{left:500px;bottom:147px;}
#t28_4{left:515px;bottom:147px;}
#t29_4{left:528px;bottom:147px;}
#t2a_4{left:535px;bottom:147px;}
#t2b_4{left:542px;bottom:147px;letter-spacing:2.76px;}
#t2c_4{left:579px;bottom:147px;}
#t2d_4{left:586px;bottom:147px;letter-spacing:0.08px;word-spacing:-0.02px;}
#t2e_4{left:70px;bottom:128px;letter-spacing:0.09px;word-spacing:0.25px;}
#t2f_4{left:529px;bottom:128px;}
#t2g_4{left:546px;bottom:128px;}
#t2h_4{left:556px;bottom:128px;}
#t2i_4{left:561px;bottom:128px;}
#t2j_4{left:568px;bottom:128px;}
#t2k_4{left:574px;bottom:128px;}
#t2l_4{left:581px;bottom:128px;}
#t2m_4{left:587px;bottom:136px;}
#t2n_4{left:593px;bottom:135px;}
#t2o_4{left:598px;bottom:136px;}
#t2p_4{left:605px;bottom:136px;}
#t2q_4{left:611px;bottom:135px;}
#t2r_4{left:616px;bottom:136px;}
#t2s_4{left:624px;bottom:136px;}
#t2t_4{left:635px;bottom:128px;}
#t2u_4{left:655px;bottom:128px;}
#t2v_4{left:665px;bottom:136px;}
#t2w_4{left:671px;bottom:128px;}
#t2x_4{left:69px;bottom:110px;letter-spacing:0.07px;word-spacing:0.48px;}
#t2y_4{left:70px;bottom:92px;letter-spacing:0.05px;word-spacing:0.99px;}
#t2z_4{left:70px;bottom:55px;letter-spacing:0.04px;word-spacing:0.29px;}

.s0_4{font-size:12px;font-family:LinBiolinumT_g-;color:#000;}
.s1_4{font-size:15px;font-family:LinLibertineT_h3;color:#000;}
.s2_4{font-size:15px;font-family:LinLibertineT_em;color:#000;}
.s3_4{font-size:15px;font-family:LibertineMathMI_ef;color:#000;}
.s4_4{font-size:15px;font-family:txsys_hb;color:#000;}
.s5_4{font-size:15px;font-family:LinLibertineT_h3;color:#781D7D;}
.s6_4{font-size:15px;font-family:LinBiolinumTB_gw;color:#000;}
.s7_4{font-size:11px;font-family:LinLibertineT_em;color:#000;}
.s8_4{font-size:15px;font-family:LinLibertineTI_hf;color:#000;}
.s9_4{font-size:15px;font-family:txmiaX_er;color:#000;}
.sa_4{font-size:11px;font-family:LibertineMathMI7_ev;color:#000;}
.sb_4{font-size:8px;font-family:LinLibertineT_em;color:#000;}
.sc_4{font-size:11px;font-family:txsys_hb;color:#000;}
.sd_4{font-size:15px;font-family:txsyb_ey;color:#000;}
.se_4{font-size:12px;font-family:LinLibertineT_h3;color:#000;}
.t.v0_4{transform:scaleX(0.989);}
.t.v1_4{transform:scaleX(1.02);}
.t.v2_4{transform:scaleX(0.979);}
.t.v3_4{transform:scaleX(1.006);}
.t.v4_4{transform:scaleX(0.991);}
.t.v5_4{transform:scaleX(0.984);}
.t.v6_4{transform:scaleX(0.987);}
.t.v7_4{transform:scaleX(1.016);}
.t.v8_4{transform:scaleX(0.985);}
.t.v9_4{transform:scaleX(1.008);}
.t.v10_4{transform:scaleX(1.005);}
</style>
<style id="fonts4" type="text/css" >

@font-face {
	font-family: LibertineMathMI7_ev;
	src: url("fonts/LibertineMathMI7_ev.woff") format("woff");
}

@font-face {
	font-family: LibertineMathMI_ef;
	src: url("fonts/LibertineMathMI_ef.woff") format("woff");
}

@font-face {
	font-family: LinBiolinumTB_gw;
	src: url("fonts/LinBiolinumTB_gw.woff") format("woff");
}

@font-face {
	font-family: LinBiolinumT_g-;
	src: url("fonts/LinBiolinumT_g-.woff") format("woff");
}

@font-face {
	font-family: LinLibertineTI_hf;
	src: url("fonts/LinLibertineTI_hf.woff") format("woff");
}

@font-face {
	font-family: LinLibertineT_em;
	src: url("fonts/LinLibertineT_em.woff") format("woff");
}

@font-face {
	font-family: LinLibertineT_h3;
	src: url("fonts/LinLibertineT_h3.woff") format("woff");
}

@font-face {
	font-family: txmiaX_er;
	src: url("fonts/txmiaX_er.woff") format("woff");
}

@font-face {
	font-family: txsyb_ey;
	src: url("fonts/txsyb_ey.woff") format("woff");
}

@font-face {
	font-family: txsys_hb;
	src: url("fonts/txsys_hb.woff") format("woff");
}

</style>
<div id="pg4Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg4" style="-webkit-user-select: none;"><svg id="pdf4" width="742" height="1100" viewBox="0 0 742 1100" style="width:742px; height:1100px; z-index: 0; isolation: isolate;" version="1.1" xmlns="http://www.w3.org/2000/svg">
<defs>
</defs>
</svg></div>
<div class="text-container"><span id="t1_4" class="t s0_4">187:4 </span><span id="t2_4" class="t s0_4">Tom Yuviler and Dana Drachsler-Cohen </span>
<span id="t3_4" class="t v0_4 s1_4" data-mappings='[[47,"fl"],[92,"fl"]]'>mitigate it, we adapt the sketch by planting a ﬂag in the ordering. When OPPSLA reaches the ﬂag, </span>
<span id="t4_4" class="t s1_4" data-mappings='[[32,"fi"]]'>it considers perturbations of a ﬁner granularity only to the most prominent pixel locations. </span>
<span id="t5_4" class="t v1_4 s1_4">We evaluate OPPSLA on several CIFAR-10 and ImageNet networks, consisting of millions of </span>
<span id="t6_4" class="t v2_4 s1_4">parameters. We show that OPPSLA obtains a state-of-the-art success rate compared to existing one </span>
<span id="t7_4" class="t v2_4 s1_4" data-mappings='[[41,"fi"]]'>pixel attacks. Further, it requires signiﬁcantly fewer queries than Sparse-RS, the current state-of-the- </span>
<span id="t8_4" class="t v2_4 s1_4" data-mappings='[[84,"fi"]]'>art attack that minimizes the number of queries. For example, on our CIFAR-10 classiﬁers, given 100 </span>
<span id="t9_4" class="t v3_4 s1_4">queries, OPPSLA obtains a success rate of 43%, while Sparse-RS obtains only 27%. To understand </span>
<span id="ta_4" class="t v2_4 s1_4" data-mappings='[[5,"ff"]]'>the eﬀectiveness of our conditions, we compare to the constant program that has no conditions and </span>
<span id="tb_4" class="t s1_4">relies on the initial prioritization. Note that this program and OPPSLA’s programs have the same </span>
<span id="tc_4" class="t v2_4 s1_4">success rate. We show that OPPSLA’s programs require 3x fewer queries than the constant program. </span>
<span id="td_4" class="t v2_4 s1_4">We further study the transferability of adversarial programs. An adversarial program is transferable </span>
<span id="te_4" class="t v1_4 s1_4" data-mappings='[[33,"ff"]]'>if, when executed on a network diﬀerent from the one used during the synthesis process, the </span>
<span id="tf_4" class="t v2_4 s1_4">program requires a similar number of queries to generate successful adversarial examples. We show </span>
<span id="tg_4" class="t v2_4 s1_4">that, when transferring an adversarial program to another network, the number of queries increases </span>
<span id="th_4" class="t v2_4 s1_4">by </span><span id="ti_4" class="t v2_4 s2_4">46% </span><span id="tj_4" class="t v2_4 s1_4">compared to the number of queries required for its original network. Namely, the number of </span>
<span id="tk_4" class="t v2_4 s1_4">queries is still an order of magnitude lower than the number of queries of existing one pixel attacks. </span>
<span id="tl_4" class="t v1_4 s1_4">This makes our adversarial programs practical, because attackers need not synthesize a unique </span>
<span id="tm_4" class="t s1_4">adversarial program for every network. We further show that the number of queries posed to the </span>
<span id="tn_4" class="t v2_4 s1_4" data-mappings='[[6,"fi"]]'>classiﬁer during the synthesis is relatively low and that OPPSLA can be integrated in an adversarial </span>
<span id="to_4" class="t s1_4" data-mappings='[[45,"fi"]]'>training to increase the robustness of classiﬁers to its attack. Lastly, we evaluate OPPSLA for few </span>
<span id="tp_4" class="t v4_4 s1_4">pixel attacks allowing up to </span><span id="tq_4" class="t s3_4"> </span><span id="tr_4" class="t s4_4">∈{</span><span id="ts_4" class="t v4_4 s2_4">2</span><span id="tt_4" class="t s3_4">,..., </span><span id="tu_4" class="t v4_4 s2_4">20</span><span id="tv_4" class="t s4_4">} </span><span id="tw_4" class="t v4_4 s1_4">perturbed pixels. We compare to CornerSearch [</span><span id="tx_4" class="t v4_4 s5_4">Croce </span>
<span id="ty_4" class="t v1_4 s5_4">and Hein 2019</span><span id="tz_4" class="t v1_4 s1_4">], the state-of-the-art for computing few pixel attacks minimizing the number of </span>
<span id="t10_4" class="t s1_4">perturbed pixels. We show that OPPSLA requires 4.7x fewer queries. </span>
<span id="t11_4" class="t s1_4">To conclude, our main contributions are: </span>
<span id="t12_4" class="t s4_4">• </span><span id="t13_4" class="t v1_4 s1_4" data-mappings='[[76,"fi"]]'>A space of programs for computing one pixel attacks. The program space is deﬁned by a </span>
<span id="t14_4" class="t v2_4 s1_4" data-mappings='[[24,"fi"]]'>sketch, guaranteeing to ﬁnd an adversarial example, if exists. The missing parts of the sketch </span>
<span id="t15_4" class="t v5_4 s1_4">are conditions, whose language consists of constraints over pixel locations, pixel values, and </span>
<span id="t16_4" class="t s1_4">the network’s output for the submitted candidates. </span>
<span id="t17_4" class="t s4_4">• </span><span id="t18_4" class="t v2_4 s1_4">OPPSLA, a program synthesizer that employs a stochastic search, inspired by the Metropolis- </span>
<span id="t19_4" class="t v6_4 s1_4">Hastings algorithm, that instantiates the sketch with grammatically correct conditions, such </span>
<span id="t1a_4" class="t s1_4">that the corresponding program minimizes the number of queries to the network. </span>
<span id="t1b_4" class="t s4_4">• </span><span id="t1c_4" class="t v2_4 s1_4">Two extensions of OPPSLA: (1) a few pixel attack minimizing the number of perturbed pixels, </span>
<span id="t1d_4" class="t s1_4" data-mappings='[[39,"fi"]]'>and (2) a one pixel attack considering ﬁner granularity perturbations. </span>
<span id="t1e_4" class="t s4_4">• </span><span id="t1f_4" class="t v7_4 s1_4">An extensive evaluation over several CIFAR-10 and ImageNet networks. The results show </span>
<span id="t1g_4" class="t v1_4 s1_4">that OPPSLA obtains a state-of-the-art success rate for one pixel attacks with an order of </span>
<span id="t1h_4" class="t v1_4 s1_4">magnitude fewer queries. Results also show that adversarial programs are transferable to </span>
<span id="t1i_4" class="t s1_4">other networks and that OPPSLA requires 4.7x fewer queries to compute few pixel attacks. </span>
<span id="t1j_4" class="t s6_4">2 </span><span id="t1k_4" class="t s6_4">PROBLEM DEFINITION </span>
<span id="t1l_4" class="t s1_4" data-mappings='[[22,"fi"],[90,"fi"]]'>In this section, we deﬁne our problem. We begin with a background on neural network classiﬁers </span>
<span id="t1m_4" class="t s1_4">and </span><span id="t1n_4" class="t s3_4"> </span>
<span id="t1o_4" class="t s7_4">0 </span>
<span id="t1p_4" class="t s1_4" data-mappings='[[40,"fi"]]'>adversarial attacks. We then formally deﬁne our problem and discuss existing approaches. </span>
<span id="t1q_4" class="t v8_4 s8_4" data-mappings='[[21,"fi"]]'>Neural network classiﬁers. </span><span id="t1r_4" class="t v8_4 s1_4" data-mappings='[[18,"fi"]]'>We focus on classiﬁers for colored two-dimensional images, although </span>
<span id="t1s_4" class="t v9_4 s1_4">our approach can be easily adapted to gray-scaled images. A colored image is a </span><span id="t1t_4" class="t s3_4"> </span>
<span id="t1u_4" class="t s7_4">1 </span>
<span id="t1v_4" class="t s4_4">× </span><span id="t1w_4" class="t s3_4"> </span>
<span id="t1x_4" class="t s7_4">2 </span>
<span id="t1y_4" class="t v9_4 s1_4">matrix of </span>
<span id="t1z_4" class="t v10_4 s1_4">pixels, where a pixel is an RGB triple in </span><span id="t20_4" class="t s4_4">[</span><span id="t21_4" class="t v10_4 s2_4">0</span><span id="t22_4" class="t s3_4">, </span><span id="t23_4" class="t v10_4 s2_4">1</span><span id="t24_4" class="t s4_4">] </span>
<span id="t25_4" class="t s7_4">3 </span>
<span id="t26_4" class="t v10_4 s1_4">. Given a set of classes </span><span id="t27_4" class="t s3_4"> </span><span id="t28_4" class="t s9_4">= </span><span id="t29_4" class="t s4_4">{</span><span id="t2a_4" class="t v10_4 s2_4">1</span><span id="t2b_4" class="t s3_4">,..., </span><span id="t2c_4" class="t s4_4">}</span><span id="t2d_4" class="t v10_4 s1_4" data-mappings='[[10,"fi"]]'>, a classiﬁer is </span>
<span id="t2e_4" class="t v1_4 s1_4">a function mapping an image to a score vector over the possible classes </span><span id="t2f_4" class="t s3_4"> </span><span id="t2g_4" class="t v1_4 s2_4">: </span><span id="t2h_4" class="t s4_4">[</span><span id="t2i_4" class="t v1_4 s2_4">0</span><span id="t2j_4" class="t s3_4">, </span><span id="t2k_4" class="t v1_4 s2_4">1</span><span id="t2l_4" class="t s4_4">] </span>
<span id="t2m_4" class="t sa_4"> </span>
<span id="t2n_4" class="t sb_4">1 </span>
<span id="t2o_4" class="t sc_4">×</span><span id="t2p_4" class="t sa_4"> </span>
<span id="t2q_4" class="t sb_4">2 </span>
<span id="t2r_4" class="t sc_4">×</span><span id="t2s_4" class="t s7_4">3 </span>
<span id="t2t_4" class="t s4_4">→ </span><span id="t2u_4" class="t sd_4">R </span>
<span id="t2v_4" class="t sa_4"> </span>
<span id="t2w_4" class="t v1_4 s1_4">. </span>
<span id="t2x_4" class="t v1_4 s1_4" data-mappings='[[18,"fi"]]'>We focus on classiﬁers implemented by a neural network. A network consists of layers, where </span>
<span id="t2y_4" class="t v1_4 s1_4" data-mappings='[[4,"fi"]]'>the ﬁrst layer is the input layer, taking an image and passing it to the next layer, and the last </span>
<span id="t2z_4" class="t se_4">Proc. ACM Program. Lang., Vol. 7, No. PLDI, Article 187. Publication date: June 2023. </span></div>

</div>
</body>
</html>
